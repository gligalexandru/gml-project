{
 "cells": [
  {
   "cell_type": "code",
   "id": "b50dfc30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:12:20.006470Z",
     "start_time": "2025-10-14T10:12:08.414799Z"
    }
   },
   "source": [
    "import os, math, numpy as np, pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import SAGEConv, GCNConv\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:12:34.282388Z",
     "start_time": "2025-10-14T10:12:34.274390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, torch\n",
    "\n",
    "print(\"exe:\", sys.executable)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda build:\", torch.version.cuda)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"gpu:\", torch.cuda.get_device_name(0))"
   ],
   "id": "fee3e263e5c20205",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exe: C:\\Users\\Alice\\PycharmProjects\\co-simulation-code\\.venv1\\Scripts\\python.exe\n",
      "torch: 2.5.1+cu121\n",
      "cuda build: 12.1\n",
      "cuda available: True\n",
      "gpu: NVIDIA GeForce RTX 4070 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:12:36.227252Z",
     "start_time": "2025-10-14T10:12:36.223018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys, os, torch, site, pkgutil, importlib\n",
    "print(\"exe:\", sys.executable)\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torch file:\", torch.__file__)\n",
    "print(\"PYTORCH_FORCE_CPU:\", os.environ.get(\"PYTORCH_FORCE_CPU\"))\n",
    "print(\"site-packages:\", site.getsitepackages())\n",
    "print(\"user site:\", site.getusersitepackages())\n",
    "#print(sys.path)  # uncomment if needed\n"
   ],
   "id": "5c0caf5fac66ccad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exe: C:\\Users\\Alice\\PycharmProjects\\co-simulation-code\\.venv1\\Scripts\\python.exe\n",
      "torch version: 2.5.1+cu121\n",
      "torch file: C:\\Users\\Alice\\PycharmProjects\\co-simulation-code\\.venv1\\Lib\\site-packages\\torch\\__init__.py\n",
      "PYTORCH_FORCE_CPU: None\n",
      "site-packages: ['C:\\\\Users\\\\Alice\\\\PycharmProjects\\\\co-simulation-code\\\\.venv1', 'C:\\\\Users\\\\Alice\\\\PycharmProjects\\\\co-simulation-code\\\\.venv1\\\\Lib\\\\site-packages']\n",
      "user site: C:\\Users\\Alice\\AppData\\Roaming\\Python\\Python311\\site-packages\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:12:38.457587Z",
     "start_time": "2025-10-14T10:12:38.452632Z"
    }
   },
   "cell_type": "code",
   "source": "import sys; print(sys.version)\n",
   "id": "4c0e03b18e90cb55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.9 (tags/v3.11.9:de54cf5, Apr  2 2024, 10:12:12) [MSC v.1938 64 bit (AMD64)]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:13:21.283540Z",
     "start_time": "2025-10-14T10:12:39.446921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_df  = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n"
   ],
   "id": "8d9668135e35726e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "641eae75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:13:24.357814Z",
     "start_time": "2025-10-14T10:13:24.351843Z"
    }
   },
   "source": [
    "# Your edge feature columns (adjust if you want more/less)\n",
    "EDGE_COLS = [\n",
    "    'Bwd Packet Length Min', 'Protocol_6', 'Bwd Packets/s', 'FWD Init Win Bytes',\n",
    "    'Packet Length Std', 'FIN Flag Count', 'SrcPortRange_registered',\n",
    "    'Packet Length Min', 'Fwd Seg Size Min', 'DstPortRange_well_known',\n",
    "    'Bwd IAT Total', 'SYN Flag Count', 'Bwd Packet Length Std'\n",
    "]\n",
    "ID_COLS = ['Src IP','Dst IP','Timestamp']\n",
    "LABEL_COL = 'target'   # binary {0,1}\n",
    "\n",
    "# Time encoding (periods in seconds)\n",
    "def time_posenc(t, periods=(60, 300, 3600)):\n",
    "    # t: numpy array of epoch seconds\n",
    "    feats = []\n",
    "    for P in periods:\n",
    "        w = 2*math.pi/P\n",
    "        feats.append(np.sin(w*t))\n",
    "        feats.append(np.cos(w*t))\n",
    "    return np.stack(feats, axis=1)  # [N, 2*len(periods)]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "34c6dedf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:13:27.008102Z",
     "start_time": "2025-10-14T10:13:26.389209Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from typing import DefaultDict\n",
    "# â† add this where build_snapshots is defined (same file)\n",
    "# (If you only call build_snapshots, add it at the top of that module/notebook cell.)\n",
    "\n",
    "def bin_time(df, bin_seconds=300):\n",
    "    # Expect df['Timestamp'] as datetime or string; convert to seconds\n",
    "    ts = pd.to_datetime(df['Timestamp'], errors='coerce', utc=True).astype('int64') // 10**9\n",
    "    df = df.copy()\n",
    "    df['_epoch'] = ts\n",
    "    df['_bin'] = (ts // bin_seconds).astype(int)\n",
    "    return df\n",
    "\n",
    "def build_snapshots(df, scaler_edge=None, fit_scaler=False, bin_seconds=300, device='cpu'):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      snapshots: list[Data] in time order\n",
    "      ip2idx: dict mapping IP -> node index (per full dataset, stable across train/test)\n",
    "      scaler_edge: fitted StandardScaler for edge features\n",
    "      edge_cols_kept: list of columns used (existing + non-NA)\n",
    "    \"\"\"\n",
    "    # Keep only available columns\n",
    "    edge_cols = [c for c in EDGE_COLS if c in df.columns]\n",
    "    cols_needed = ID_COLS + edge_cols + [LABEL_COL]\n",
    "    cols_needed = [c for c in cols_needed if c in df.columns]\n",
    "    df = df[cols_needed].dropna(subset=['Src IP','Dst IP'])\n",
    "    df = bin_time(df, bin_seconds=bin_seconds)\n",
    "\n",
    "    # Edge feature scaler\n",
    "    if scaler_edge is None:\n",
    "        scaler_edge = StandardScaler()\n",
    "        fit_scaler = True\n",
    "    if fit_scaler:\n",
    "        scaler_edge.fit(df[edge_cols].astype(float).values)\n",
    "\n",
    "    # Stable node indexing across all snapshots in this split\n",
    "    ips = pd.Index(pd.unique(pd.concat([df['Src IP'], df['Dst IP']])))\n",
    "    ip2idx = {ip:i for i,ip in enumerate(ips)}\n",
    "\n",
    "    snapshots = []\n",
    "    # For 1-bin lag activity: track per-node edge count in previous bin\n",
    "    prev_activity = defaultdict(int)\n",
    "\n",
    "    for b, g in df.sort_values('_bin').groupby('_bin'):\n",
    "        # Map nodes\n",
    "        src = g['Src IP'].map(ip2idx).astype(int).values\n",
    "        dst = g['Dst IP'].map(ip2idx).astype(int).values\n",
    "        edge_index = torch.tensor(np.vstack([src, dst]), dtype=torch.long)\n",
    "\n",
    "        # Edge attributes = scaled flow features + time encoding\n",
    "        eX = scaler_edge.transform(g[edge_cols].astype(float).values)\n",
    "        tfe = time_posenc(g['_epoch'].values)  # [E, 2*len(periods)]\n",
    "        edge_attr = torch.tensor(np.hstack([eX, tfe]), dtype=torch.float)\n",
    "\n",
    "        # Labels (edge-level)\n",
    "        y = torch.tensor(g[LABEL_COL].astype(int).values, dtype=torch.long)\n",
    "\n",
    "        # Node features (inductive, not learned):\n",
    "        #   in/out/total degree in THIS snapshot + previous-bin activity count\n",
    "        n_nodes = len(ip2idx)\n",
    "        out_deg = np.bincount(src, minlength=n_nodes)\n",
    "        in_deg  = np.bincount(dst, minlength=n_nodes)\n",
    "        deg     = (out_deg + in_deg).reshape(-1,1)\n",
    "        node_feat = np.hstack([\n",
    "            in_deg.reshape(-1,1),\n",
    "            out_deg.reshape(-1,1),\n",
    "            deg,\n",
    "            np.array([prev_activity[i] for i in range(n_nodes)]).reshape(-1,1)\n",
    "        ])\n",
    "        # log1p to compress scale\n",
    "        node_feat = np.log1p(node_feat)\n",
    "        x = torch.tensor(node_feat, dtype=torch.float)\n",
    "\n",
    "        data = Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=y\n",
    "        )\n",
    "        # Store mapping to recover edge order if needed\n",
    "        data._bin = int(b)\n",
    "        snapshots.append(data)\n",
    "\n",
    "        # Update prev_activity for next bin (count edges touched by node this bin)\n",
    "        touched = np.bincount(np.concatenate([src, dst]), minlength=n_nodes)\n",
    "        for i, c in enumerate(touched):\n",
    "            prev_activity[i] = int(c)\n",
    "\n",
    "    # Move to device lazily in loader/training\n",
    "    return snapshots, ip2idx, scaler_edge, edge_cols + [f'time_{i}' for i in range(tfe.shape[1])]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "afd2cfea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:13:30.079076Z",
     "start_time": "2025-10-14T10:13:30.065726Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATv2Conv, LayerNorm\n",
    "\n",
    "class GraphTimeEdgeClassifier(nn.Module):\n",
    "    def __init__(self, in_node, in_edge, hidden=64, gnn='sage',\n",
    "                 num_layers=2, dropout=0.2, gat_heads=4,\n",
    "                 use_edge_attr_in_gat=True, pair_mode='concat'):\n",
    "        \"\"\"\n",
    "        gnn: 'gcn' | 'sage' | 'gat'\n",
    "        pair_mode: 'concat' (h_i || h_j), 'concat+diff+had' (richer), or 'had' (h_i * h_j)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.gnn = gnn\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pair_mode = pair_mode\n",
    "        self.hidden = hidden\n",
    "        self.in_edge = in_edge\n",
    "        self.gat_heads = gat_heads\n",
    "        self.use_edge_attr_in_gat = use_edge_attr_in_gat\n",
    "\n",
    "        # --- conv factory\n",
    "        def make_conv(i, o):\n",
    "            if gnn == 'gcn':\n",
    "                return GCNConv(i, o, normalize=True)\n",
    "            elif gnn == 'sage':\n",
    "                return SAGEConv(i, o)\n",
    "            elif gnn == 'gat':\n",
    "                # keep output dim = hidden by concatenating heads\n",
    "                out_per_head = o // gat_heads\n",
    "                assert o % gat_heads == 0, \"hidden must be divisible by gat_heads\"\n",
    "                return GATv2Conv(\n",
    "                    in_channels=i,\n",
    "                    out_channels=out_per_head,\n",
    "                    heads=gat_heads,\n",
    "                    concat=True,\n",
    "                    edge_dim=(in_edge if use_edge_attr_in_gat else None)\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\"gnn must be 'gcn', 'sage', or 'gat'\")\n",
    "\n",
    "        # --- layers\n",
    "        dims = [in_node] + [hidden] * num_layers\n",
    "        self.convs = nn.ModuleList([make_conv(dims[i], dims[i+1]) for i in range(num_layers)])\n",
    "        self.norms = nn.ModuleList([LayerNorm(hidden) for _ in range(num_layers)])\n",
    "\n",
    "        # --- edge head input dim based on pairing\n",
    "        if pair_mode == 'concat':\n",
    "            edge_in = 2*hidden + in_edge\n",
    "        elif pair_mode == 'concat+diff+had':\n",
    "            edge_in = (2*hidden + hidden + hidden) + in_edge  # h_i||h_j||(h_i-h_j)||(h_i*h_j)\n",
    "        elif pair_mode == 'had':\n",
    "            edge_in = hidden + in_edge                        # (h_i*h_j)||edge_attr\n",
    "        else:\n",
    "            raise ValueError(\"pair_mode not recognized\")\n",
    "\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(edge_in, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, 2)\n",
    "        )\n",
    "\n",
    "    def node_encode(self, x, edge_index, edge_attr):\n",
    "        for l, conv in enumerate(self.convs):\n",
    "            h_in = x\n",
    "            if self.gnn == 'gat':\n",
    "                x = conv(x, edge_index, edge_attr=edge_attr if self.use_edge_attr_in_gat else None)\n",
    "            else:\n",
    "                x = conv(x, edge_index)\n",
    "            x = self.norms[l](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            # simple residual if dims match\n",
    "            if h_in.shape == x.shape:\n",
    "                x = x + h_in\n",
    "        return x  # [N, hidden]\n",
    "\n",
    "    def pair_edges(self, x, edge_index, edge_attr):\n",
    "        src, dst = edge_index\n",
    "        h_i, h_j = x[src], x[dst]          # [E, hidden], [E, hidden]\n",
    "        if self.pair_mode == 'concat':\n",
    "            z = torch.cat([h_i, h_j, edge_attr], dim=1)\n",
    "        elif self.pair_mode == 'concat+diff+had':\n",
    "            z = torch.cat([h_i, h_j, h_i - h_j, h_i * h_j, edge_attr], dim=1)\n",
    "        else:  # 'had'\n",
    "            z = torch.cat([h_i * h_j, edge_attr], dim=1)\n",
    "        return z\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.node_encode(x, edge_index, edge_attr)          # [N, hidden]\n",
    "        z = self.pair_edges(x, edge_index, edge_attr)           # [E, ...]\n",
    "        logits = self.edge_mlp(z)                               # [E, 2]\n",
    "        return logits\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "613f402f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:13:33.724068Z",
     "start_time": "2025-10-14T10:13:33.715072Z"
    }
   },
   "source": [
    "def run_epoch(model, snapshots, optimizer=None, device='cpu', weights=None):\n",
    "    is_train = optimizer is not None\n",
    "    total_loss, total_correct, total_edges = 0.0, 0, 0\n",
    "    ce = nn.CrossEntropyLoss(weight=weights)   # <--- use weights\n",
    "\n",
    "    for data in snapshots:\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "        if is_train:\n",
    "            loss = ce(logits, data.y)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "            optimizer.step()\n",
    "            total_loss += float(loss.item()) * data.y.numel()\n",
    "        with torch.no_grad():\n",
    "            pred = logits.argmax(dim=1)\n",
    "            total_correct += int((pred == data.y).sum())\n",
    "            total_edges += int(data.y.numel())\n",
    "\n",
    "    avg_loss = total_loss / max(1, total_edges) if is_train else None\n",
    "    acc = total_correct / max(1, total_edges)\n",
    "    return avg_loss, acc\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "7d0cb845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T07:17:55.499126Z",
     "start_time": "2025-10-14T07:16:35.242073Z"
    }
   },
   "source": [
    "\n",
    "test_df  = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:13:36.387383Z",
     "start_time": "2025-10-14T10:13:36.384225Z"
    }
   },
   "cell_type": "code",
   "source": "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
   "id": "3d91a1e44d14e825",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:13:38.246113Z",
     "start_time": "2025-10-14T10:13:38.242615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import torch\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda:\", torch.version.cuda)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n"
   ],
   "id": "177981b4acb55861",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.5.1+cu121\n",
      "cuda: 12.1\n",
      "cuda available: True\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "515b5084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:15:41.702974Z",
     "start_time": "2025-10-14T10:13:40.407337Z"
    }
   },
   "source": [
    "# Assume you already have train_df and test_df with the listed columns\n",
    "# Build train snapshots (fit scaler)\n",
    "import numpy as np\n",
    "\n",
    "train_snaps, train_ip2idx, scaler_edge, edge_cols_used = build_snapshots(\n",
    "    train_df, scaler_edge=None, fit_scaler=True, bin_seconds=300, device=device\n",
    ")\n",
    "\n",
    "# Build test snapshots (reuse scaler; allow different IP set)\n",
    "# To preserve strict inductive setting, we build a separate ip2idx for test (no shared node IDs).\n",
    "test_snaps, test_ip2idx, _, _ = build_snapshots(\n",
    "    test_df, scaler_edge=scaler_edge, fit_scaler=False, bin_seconds=300, device=device\n",
    ")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:16:15.654672Z",
     "start_time": "2025-10-14T10:16:15.644243Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aa27834875cdd87c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:16:18.973047Z",
     "start_time": "2025-10-14T10:16:18.969044Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1fcd4b442c95316d",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6ddbc030490fd6ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:16:21.764531Z",
     "start_time": "2025-10-14T10:16:21.176255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- imports you need ---\n",
    "import torch, numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# ---------- weights from class imbalance ----------\n",
    "def class_weights_from_snaps(snaps, device=\"cpu\"):\n",
    "    \"\"\"\n",
    "    Returns a tensor([w0, w1]) so positives are up-weighted:\n",
    "    w1 = (#negatives / #positives). Safe if no positives.\n",
    "    \"\"\"\n",
    "    neg = pos = 0\n",
    "    for d in snaps:\n",
    "        y = d.y\n",
    "        neg += int((y == 0).sum())\n",
    "        pos += int((y == 1).sum())\n",
    "    w1 = (neg / max(1, pos)) if pos > 0 else 1.0\n",
    "    return torch.tensor([1.0, float(w1)], dtype=torch.float32, device=device)\n",
    "\n",
    "# ---------- quick PR-AUC evaluator (used by early stopping) ----------\n",
    "@torch.no_grad()\n",
    "def _pr_auc(model, snaps, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    for d in snaps:\n",
    "        y = d.y\n",
    "        if not ((y == 0).any() and (y == 1).any()):   # skip single-class snapshots\n",
    "            continue\n",
    "        d = d.to(device)\n",
    "        p1 = torch.softmax(model(d), dim=1)[:, 1].cpu().numpy()\n",
    "        ys.append(y.cpu().numpy()); ps.append(p1)\n",
    "    if not ys:\n",
    "        return float(\"nan\")\n",
    "    y = np.concatenate(ys); p = np.concatenate(ps)\n",
    "    return average_precision_score(y, p)\n",
    "\n",
    "# ---------- training loop with early stopping on PR-AUC ----------\n",
    "def train_one(model, snaps_train, snaps_val, device=\"cpu\",\n",
    "              lr=1e-3, wd=1e-5, epochs=10, patience=2,\n",
    "              weights=None, grad_clip=0.5):\n",
    "    \"\"\"\n",
    "    Trains `model` on a list of PyG Data snapshots.\n",
    "    Early-stops by PR-AUC on `snaps_val`. Returns the best PR-AUC.\n",
    "    \"\"\"\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    ce  = torch.nn.CrossEntropyLoss(weight=weights)\n",
    "\n",
    "    best, best_state, wait = -1.0, None, 0\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        for d in snaps_train:\n",
    "            d = d.to(device, non_blocking=True)\n",
    "            loss = ce(model(d), d.y)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            if grad_clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            opt.step()\n",
    "\n",
    "        pr = _pr_auc(model, snaps_val, device)\n",
    "        if pr > best:\n",
    "            best, best_state, wait = pr, {k: v.detach().cpu() for k, v in model.state_dict().items()}, 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict({k: v.to(device) for k, v in best_state.items()})\n",
    "    return best\n"
   ],
   "id": "396b31bb1b015550",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:16:54.382011Z",
     "start_time": "2025-10-14T10:16:25.219326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------- SPEED & MEMORY KNOBS ----------\n",
    "FAST = True\n",
    "\n",
    "if FAST:\n",
    "    N_TRIALS          = 6\n",
    "    N_SPLITS          = 2\n",
    "    EPOCHS            = 3\n",
    "    PATIENCE          = 1\n",
    "    MAX_EDGES         = 3_000   # <- keep comment on same line to avoid indent issues\n",
    "    NEG_FRAC          = 0.2\n",
    "    TRAIN_MAX_SNAPS   = 30      # limit # of snapshots per fold\n",
    "    VAL_MAX_SNAPS     = 12\n",
    "    BINS_STRIDE       = 2       # use every 2nd bin during tuning\n",
    "else:\n",
    "    N_TRIALS          = 25\n",
    "    N_SPLITS          = 5\n",
    "    EPOCHS            = 10\n",
    "    PATIENCE          = 2\n",
    "    MAX_EDGES         = 20_000\n",
    "    NEG_FRAC          = 0.5\n",
    "    TRAIN_MAX_SNAPS   = 99999\n",
    "    VAL_MAX_SNAPS     = 99999\n",
    "    BINS_STRIDE       = 1\n",
    "\n",
    "# ---------- PREP: keep minimal columns + downcast to float32 ----------\n",
    "import gc, pandas as pd, numpy as np, warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "def _minimal(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    edge_cols = [c for c in EDGE_COLS if c in df.columns]\n",
    "    cols = [c for c in (ID_COLS + edge_cols + [LABEL_COL]) if c in df.columns]\n",
    "    out = df[cols].copy()\n",
    "\n",
    "    # downcast floats to float32 to halve memory\n",
    "    for c in edge_cols:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\").astype(np.float32)\n",
    "    return out\n",
    "\n",
    "BIN_SECS = 300\n",
    "\n",
    "train_min = _minimal(train_df)\n",
    "test_min  = _minimal(test_df)\n",
    "\n",
    "train_binned = bin_time(train_min, BIN_SECS).sort_values('_bin')\n",
    "test_binned  = bin_time(test_min,  BIN_SECS).sort_values('_bin')\n",
    "\n",
    "train_bins_all = train_binned['_bin'].unique()\n",
    "test_bins_all  = test_binned['_bin'].unique()\n",
    "\n",
    "def df_from_bins_prebinned(df_binned: pd.DataFrame, bins_sel):\n",
    "    # select rows for bins_sel; no extra column drops (build_snapshots selects what it needs)\n",
    "    return df_binned[df_binned['_bin'].isin(set(bins_sel))]\n",
    "\n",
    "def make_snaps_for_bins(df_binned, bins_sel, scaler_edge=None, fit=False, device=\"cpu\"):\n",
    "    sub_df = df_from_bins_prebinned(df_binned, bins_sel)\n",
    "    snaps, _, scaler, _ = build_snapshots(\n",
    "        sub_df, scaler_edge=scaler_edge, fit_scaler=fit, bin_seconds=BIN_SECS, device=device\n",
    "    )\n",
    "    return snaps, scaler\n",
    "\n",
    "# ---------- UTIL: stratified edge sampler & snapshot cap ----------\n",
    "import torch\n",
    "def sample_edges_stratified(data, pos_frac=1.0, neg_frac=0.2, max_edges=None):\n",
    "    y = data.y\n",
    "    pos = torch.nonzero(y == 1).view(-1)\n",
    "    neg = torch.nonzero(y == 0).view(-1)\n",
    "    kpos = len(pos) if pos_frac >= 1 else max(1, int(len(pos)*pos_frac)) if len(pos)>0 else 0\n",
    "    kneg = len(neg) if neg_frac >= 1 else max(1, int(len(neg)*neg_frac)) if len(neg)>0 else 0\n",
    "    keep = torch.cat([\n",
    "        pos[torch.randperm(len(pos))[:kpos]] if len(pos)>0 else pos,\n",
    "        neg[torch.randperm(len(neg))[:kneg]] if len(neg)>0 else neg\n",
    "    ])\n",
    "    if keep.numel() == 0: return data\n",
    "    if max_edges is not None and keep.numel() > max_edges:\n",
    "        keep = keep[torch.randperm(keep.numel())[:max_edges]]\n",
    "\n",
    "    d = data.clone()\n",
    "    d.edge_index = d.edge_index[:, keep]\n",
    "    if getattr(d, \"edge_attr\", None) is not None:\n",
    "        d.edge_attr = d.edge_attr[keep]\n",
    "    d.y = d.y[keep]\n",
    "    return d\n",
    "\n",
    "def has_both_classes(d) -> bool:\n",
    "    y = d.y.view(-1)\n",
    "    return bool((y == 0).any().item() and (y == 1).any().item())\n",
    "\n",
    "def cap_snaps(snaps, k):\n",
    "    return snaps[:k] if (k is not None and len(snaps) > k) else snaps\n",
    "\n",
    "# ---------- OPTUNA OBJECTIVE (memory-savvy) ----------\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "def objective(trial):\n",
    "    print(f\"[optuna] trial {trial.number} start\", flush=True)\n",
    "\n",
    "    gnn        = trial.suggest_categorical(\"gnn\", [\"sage\",\"gcn\",\"gat\"])\n",
    "    hidden     = trial.suggest_categorical(\"hidden\", [32, 64, 128])\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 3)\n",
    "    dropout    = trial.suggest_float(\"dropout\", 0.1, 0.4)\n",
    "    lr         = trial.suggest_float(\"lr\", 5e-4, 2e-3, log=True)\n",
    "    wd         = trial.suggest_float(\"weight_decay\", 1e-8, 1e-4, log=True)\n",
    "    gat_heads  = trial.suggest_categorical(\"gat_heads\", [2,4]) if gnn == \"gat\" else 2\n",
    "    pair_mode  = \"concat\"\n",
    "\n",
    "    bins = train_bins_all[::BINS_STRIDE]  # stride bins for speed\n",
    "    tscv = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "\n",
    "    scores = []\n",
    "    for fold, (tr_idx, va_idx) in enumerate(tscv.split(range(len(bins)))):\n",
    "        train_bins = bins[tr_idx];  val_bins = bins[va_idx]\n",
    "\n",
    "        tr_snaps, scaler_edge = make_snaps_for_bins(train_binned, train_bins, scaler_edge=None, fit=True, device=device)\n",
    "        va_snaps, _           = make_snaps_for_bins(train_binned, val_bins,   scaler_edge=scaler_edge, fit=False, device=device)\n",
    "\n",
    "        # limit snapshots per fold (controls RAM)\n",
    "        tr_snaps = cap_snaps(tr_snaps, TRAIN_MAX_SNAPS)\n",
    "        va_snaps = cap_snaps(va_snaps, VAL_MAX_SNAPS)\n",
    "\n",
    "        # subsample edges\n",
    "        tr_snaps = [sample_edges_stratified(d, pos_frac=1.0, neg_frac=NEG_FRAC, max_edges=MAX_EDGES) for d in tr_snaps]\n",
    "        va_snaps = [sample_edges_stratified(d, pos_frac=1.0, neg_frac=NEG_FRAC, max_edges=MAX_EDGES) for d in va_snaps]\n",
    "\n",
    "        # keep only valid val snapshots\n",
    "        va_snaps = [d for d in va_snaps if has_both_classes(d)]\n",
    "        if not va_snaps or not tr_snaps:\n",
    "            # free memory before continuing\n",
    "            del tr_snaps, va_snaps; gc.collect()\n",
    "            continue\n",
    "\n",
    "        in_node = tr_snaps[0].x.size(1)\n",
    "        in_edge = tr_snaps[0].edge_attr.size(1)\n",
    "        weights = class_weights_from_snaps(tr_snaps, device)\n",
    "\n",
    "        model = GraphTimeEdgeClassifier(\n",
    "            in_node=in_node, in_edge=in_edge, hidden=hidden, gnn=gnn,\n",
    "            num_layers=num_layers, dropout=dropout, gat_heads=gat_heads,\n",
    "            use_edge_attr_in_gat=True, pair_mode=pair_mode\n",
    "        ).to(device)\n",
    "\n",
    "        score = train_one(model, tr_snaps, va_snaps, device,\n",
    "                          lr=lr, wd=wd, epochs=EPOCHS, patience=PATIENCE, weights=weights)\n",
    "        if not np.isnan(score):\n",
    "            scores.append(score)\n",
    "\n",
    "        # free memory aggressively\n",
    "        del model, tr_snaps, va_snaps, weights, scaler_edge\n",
    "        if device == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "        trial.report(float(np.mean(scores)) if scores else -1.0, step=fold)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return float(np.mean(scores)) if scores else float(\"-inf\")\n"
   ],
   "id": "c0344282616945d1",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:22:48.811998Z",
     "start_time": "2025-10-14T10:16:57.644320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pruner = optuna.pruners.HyperbandPruner(min_resource=1, max_resource=N_SPLITS, reduction_factor=3)\n",
    "study = optuna.create_study(direction=\"maximize\",\n",
    "                            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "                            pruner=pruner)\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "print(\"BEST:\", study.best_trial.params, \"score:\", study.best_trial.value)\n"
   ],
   "id": "13f18f58b703bc01",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "75513cc2629c4b0a842f5e0f073c5f50"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[optuna] trial 0 start\n",
      "[optuna] trial 1 start\n",
      "[optuna] trial 2 start\n",
      "[optuna] trial 3 start\n",
      "[optuna] trial 4 start\n",
      "[optuna] trial 5 start\n",
      "BEST: {'gnn': 'gcn', 'hidden': 32, 'num_layers': 2, 'dropout': 0.3598528437324806, 'lr': 0.0011504753106625046, 'weight_decay': 6.7965780907581515e-06} score: -inf\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:26:58.331573Z",
     "start_time": "2025-10-14T10:26:05.026102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model dims\n",
    "in_node = train_snaps[0].x.size(1)             # [in_deg, out_deg, deg, prev_activity] -> 4\n",
    "in_edge = train_snaps[0].edge_attr.size(1)     # len(EDGE_COLS_kept) + time_posenc\n",
    "model = GraphTimeEdgeClassifier( in_node, in_edge, hidden=32, gnn='gcn',\n",
    "                 num_layers=2, dropout=0.3598528437324806, gat_heads=4,\n",
    "                 use_edge_attr_in_gat=True, pair_mode='concat').to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=0.0011504753106625046, weight_decay=6.7965780907581515e-06)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_acc = run_epoch(model, train_snaps, optimizer=opt, device=device)\n",
    "    _, te_acc = run_epoch(model, test_snaps, optimizer=None, device=device)\n",
    "    print(f\"Epoch {epoch:02d} | train loss {tr_loss:.4f} | train acc {tr_acc:.4f} | test acc {te_acc:.4f}\")"
   ],
   "id": "88413c69bd376e0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss 6.4491 | train acc 0.8976 | test acc 0.8394\n",
      "Epoch 02 | train loss 0.2408 | train acc 0.9642 | test acc 0.9303\n",
      "Epoch 03 | train loss 0.0078 | train acc 0.9976 | test acc 0.9776\n",
      "Epoch 04 | train loss 0.0073 | train acc 0.9969 | test acc 0.9947\n",
      "Epoch 05 | train loss 0.0075 | train acc 0.9983 | test acc 0.9989\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "68b0057a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:27:04.982229Z",
     "start_time": "2025-10-14T10:27:04.972849Z"
    }
   },
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_with_confusion(model, snapshots, device='cpu'):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in snapshots:\n",
    "            data = data.to(device)\n",
    "            logits = model(data)\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            labels = data.y.cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    report = classification_report(all_labels, all_preds, digits=4)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Pred 0', 'Pred 1'],\n",
    "                yticklabels=['True 0', 'True 1'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix (Test Set)')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"ðŸ“Š Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return cm, report"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "9eddb0a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T10:27:15.691505Z",
     "start_time": "2025-10-14T10:27:07.228817Z"
    }
   },
   "source": "cm, report = evaluate_with_confusion(model, test_snaps, device=device)\n",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9996    0.9999    0.9998   5391219\n",
      "           1     0.9997    0.9982    0.9990   1084194\n",
      "\n",
      "    accuracy                         0.9997   6475413\n",
      "   macro avg     0.9997    0.9991    0.9994   6475413\n",
      "weighted avg     0.9997    0.9997    0.9997   6475413\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
