{
 "cells": [
  {
   "cell_type": "code",
   "id": "ff190f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:18:30.479756Z",
     "start_time": "2025-11-06T06:18:19.588713Z"
    }
   },
   "source": [
    "import os, math, numpy as np, pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pandas import read_csv\n",
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader, NeighborLoader\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import networkx as nx"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "e2d61ef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:18:30.503157Z",
     "start_time": "2025-11-06T06:18:30.497788Z"
    }
   },
   "source": [
    "\n",
    "EDGE_COLS = [\n",
    "    'Bwd Packet Length Min', 'Protocol_6', 'Bwd Packets/s', 'FWD Init Win Bytes',\n",
    "    'Packet Length Std', 'FIN Flag Count', 'SrcPortRange_registered',\n",
    "    'Packet Length Min', 'Fwd Seg Size Min', 'DstPortRange_well_known',\n",
    "    'Bwd IAT Total', 'SYN Flag Count', 'Bwd Packet Length Std'\n",
    "]\n",
    "ID_COLS = ['Src IP','Dst IP','Timestamp']\n",
    "LABEL_COL = 'target'"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T16:36:06.955226Z",
     "start_time": "2025-10-28T16:36:06.894812Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "eb214b71a3b67c5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32377064 entries, 0 to 32377063\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Dtype  \n",
      "---  ------                   -----  \n",
      " 0   Timestamp                object \n",
      " 1   Src IP                   object \n",
      " 2   Dst IP                   object \n",
      " 3   Bwd Packet Length Min    int64  \n",
      " 4   Protocol_6               bool   \n",
      " 5   Bwd Packets/s            float64\n",
      " 6   FWD Init Win Bytes       int64  \n",
      " 7   Packet Length Std        float64\n",
      " 8   FIN Flag Count           int64  \n",
      " 9   SrcPortRange_registered  bool   \n",
      " 10  Packet Length Min        int64  \n",
      " 11  Fwd Seg Size Min         int64  \n",
      " 12  DstPortRange_well_known  bool   \n",
      " 13  Bwd IAT Total            int64  \n",
      " 14  SYN Flag Count           int64  \n",
      " 15  Bwd Packet Length Std    float64\n",
      " 16  target                   int64  \n",
      "dtypes: bool(3), float64(3), int64(8), object(3)\n",
      "memory usage: 3.5+ GB\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "3662ee25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:22:06.830670Z",
     "start_time": "2025-11-06T06:22:06.819610Z"
    }
   },
   "source": [
    "# def time_posenc(t, periods=(60, 300, 3600)):\n",
    "#     # t: numpy array of epoch seconds\n",
    "#     feats = []\n",
    "#     for P in periods:\n",
    "#         w = 2*math.pi/P\n",
    "#         feats.append(np.sin(w*t))\n",
    "#         feats.append(np.cos(w*t))\n",
    "#     return np.stack(feats, axis=1)  # [N, 2*len(periods)]\n",
    "\n",
    "def bin_time(df, bin_seconds=300):\n",
    "    # Expect df['Timestamp'] as datetime or string; convert to seconds\n",
    "    ts = pd.to_datetime(df['Timestamp'], errors='coerce', utc=True).astype('int64') // 10**9\n",
    "    df = df.copy()\n",
    "    df['_epoch'] = ts\n",
    "    df['_bin'] = (ts // bin_seconds).astype(int)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "0913f22b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:18:30.534207Z",
     "start_time": "2025-11-06T06:18:30.511115Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "def compute_node_centralities_fast2(\n",
    "    df: pd.DataFrame,\n",
    "    ip2idx: dict,\n",
    "    src_col: str = \"Src IP\",\n",
    "    dst_col: str = \"Dst IP\",\n",
    "    use_betweenness: bool = False,     # set True if you have NetworKit\n",
    "    betw_samples: int = 32,            # NetworKit ApproxBetweenness samples\n",
    "    pagerank_alpha: float = 0.85,\n",
    "    pagerank_iters: int = 40,\n",
    "    pagerank_tol: float = 1e-6,\n",
    "    closeness_if_small: int = 20_000,  # only compute closeness if N <= this\n",
    "    ktruss_if_small: int = 10_000      # only compute k-truss if N <= this\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns C: [N_nodes, 5] -> [degree, betweenness, closeness, pagerank, ktruss_level], z-scored per column.\n",
    "    Fast path fills unavailable metrics with 0 (safe after z-scoring).\n",
    "    \"\"\"\n",
    "    N = len(ip2idx)\n",
    "    if N == 0:\n",
    "        return np.zeros((0,5), dtype=float)\n",
    "\n",
    "    # ------- Build sparse adjacency (directed) fast -------\n",
    "    # Map to indices without Python loops\n",
    "    src_idx = df[src_col].astype(str).map(ip2idx).to_numpy()\n",
    "    dst_idx = df[dst_col].astype(str).map(ip2idx).to_numpy()\n",
    "    mask = np.isfinite(src_idx) & np.isfinite(dst_idx)\n",
    "    src_idx = src_idx[mask].astype(np.int64, copy=False)\n",
    "    dst_idx = dst_idx[mask].astype(np.int64, copy=False)\n",
    "\n",
    "    # Remove self-loops once (optional)\n",
    "    non_self = src_idx != dst_idx\n",
    "    src_idx, dst_idx = src_idx[non_self], dst_idx[non_self]\n",
    "\n",
    "    data = np.ones_like(src_idx, dtype=np.float64)\n",
    "    A = sparse.coo_matrix((data, (src_idx, dst_idx)), shape=(N, N)).tocsr()\n",
    "\n",
    "    # ------- Degree (total degree for directed) -------\n",
    "    outdeg = A.getnnz(axis=1)          # rows\n",
    "    indeg  = A.getnnz(axis=0)          # cols\n",
    "    degree = (outdeg + indeg).astype(np.float64)\n",
    "\n",
    "    # ------- PageRank (power iteration on sparse) -------\n",
    "    # Row-normalize A^T equivalent: P^T @ pr\n",
    "    outdeg_safe = np.maximum(outdeg, 1)\n",
    "    Dinv = sparse.diags(1.0 / outdeg_safe)\n",
    "    P = Dinv @ A                       # row-stochastic (on rows)\n",
    "    pr = np.full(N, 1.0 / N, dtype=np.float64)\n",
    "    teleport = (1.0 - pagerank_alpha) / N\n",
    "    for _ in range(pagerank_iters):\n",
    "        pr_new = pagerank_alpha * (P.T @ pr) + teleport\n",
    "        if np.linalg.norm(pr_new - pr, 1) < pagerank_tol:\n",
    "            pr = pr_new\n",
    "            break\n",
    "        pr = pr_new\n",
    "\n",
    "    # ------- Betweenness (optional, NetworKit) -------\n",
    "    betw = np.zeros(N, dtype=np.float64)\n",
    "    if use_betweenness:\n",
    "        try:\n",
    "            import networkit as nk\n",
    "            # Build NetworKit graph\n",
    "            Gnk = nk.Graph(n=N, weighted=False, directed=True)\n",
    "            # Add edges (NetworKit expects int indices)\n",
    "            # Faster add: iterate CSR rows\n",
    "            rows, cols = A.nonzero()\n",
    "            for u, v in zip(rows.tolist(), cols.tolist()):\n",
    "                if u != v:\n",
    "                    Gnk.addEdge(u, v)\n",
    "            c = nk.centrality.ApproxBetweenness(Gnk, nSamples=int(betw_samples), normalized=True)\n",
    "            c.run()\n",
    "            betw = np.array(c.scores(), dtype=np.float64)\n",
    "        except Exception:\n",
    "            # If NetworKit not available, keep zeros (safe after z-score)\n",
    "            pass\n",
    "\n",
    "    # ------- Closeness (tiny graphs only, else zeros) -------\n",
    "    clos = np.zeros(N, dtype=np.float64)\n",
    "    if N <= closeness_if_small:\n",
    "        try:\n",
    "            import networkx as nx\n",
    "            H = nx.from_scipy_sparse_array(A, create_using=nx.DiGraph)\n",
    "            # Use NX fast approximation? (still Python; okay for small N)\n",
    "            clos_dict = nx.closeness_centrality(H)  # directed-version\n",
    "            # Map dict to array by index order\n",
    "            # NetworkX labels are 0..N-1 when built from scipy sparse\n",
    "            clos = np.array([clos_dict.get(i, 0.0) for i in range(N)], dtype=np.float64)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # ------- k-truss (tiny graphs only, else zeros) -------\n",
    "    ktr = np.zeros(N, dtype=np.float64)\n",
    "    if N <= ktruss_if_small:\n",
    "        try:\n",
    "            import networkx as nx\n",
    "            Hu = nx.from_scipy_sparse_array((A + A.T).sign(), create_using=nx.Graph)\n",
    "            ktr_level = np.zeros(N, dtype=np.int32)\n",
    "            for k in range(3, 7):  # modest bound; raise carefully\n",
    "                try:\n",
    "                    Tk = nx.k_truss(Hu, k)\n",
    "                except nx.NetworkXError:\n",
    "                    break\n",
    "                nodes = list(Tk.nodes())\n",
    "                if not nodes:\n",
    "                    continue\n",
    "                ktr_level[np.array(nodes, dtype=np.int64)] = np.maximum(ktr_level[np.array(nodes, dtype=np.int64)], k)\n",
    "            ktr = ktr_level.astype(np.float64)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # ------- Pack in the right slot order: [degree, betweenness, closeness, pagerank, ktruss] -------\n",
    "    C = np.column_stack([degree, betw, clos, pr, ktr])\n",
    "\n",
    "    # ------- z-score per column (robust to zeros) -------\n",
    "    mu = C.mean(axis=0, keepdims=True)\n",
    "    sd = C.std(axis=0, keepdims=True) + 1e-8\n",
    "    C = (C - mu) / sd\n",
    "    return C\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "27190bf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:18:30.898765Z",
     "start_time": "2025-11-06T06:18:30.874841Z"
    }
   },
   "source": [
    "# Fast unique IP mapping (string-safe)\n",
    "def make_ip_index(df, src_col='Src IP', dst_col='Dst IP'):\n",
    "    # Combine columns as one numpy array without concat copies\n",
    "    src = df[src_col].astype(str).to_numpy(copy=False)\n",
    "    dst = df[dst_col].astype(str).to_numpy(copy=False)\n",
    "    all_ips = np.concatenate((src, dst))\n",
    "\n",
    "    # Use pandas categorical (internally fast hash-based unique)\n",
    "    cat = pd.Categorical(all_ips)\n",
    "    ip2idx = dict(zip(cat.categories, range(len(cat.categories))))\n",
    "    n_nodes = len(ip2idx)\n",
    "    return ip2idx, n_nodes\n",
    "\n",
    "def build_snapshots(df, scaler_edge=None, fit_scaler=False, bin_seconds=300, device='cpu', include_per_bin_feats=True):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      snapshots: list[Data] in time order\n",
    "      ip2idx: dict mapping IP -> node index (per full dataset, stable across train/test)\n",
    "      scaler_edge: fitted StandardScaler for edge features\n",
    "      edge_cols_kept: list of columns used (existing + non-NA + time enc + centralities names)\n",
    "    \"\"\"\n",
    "    # Keep only available columns\n",
    "    edge_cols = [c for c in EDGE_COLS if c in df.columns]\n",
    "    cols_needed = ID_COLS + edge_cols + [LABEL_COL]\n",
    "    cols_needed = [c for c in cols_needed if c in df.columns]\n",
    "    df = df[cols_needed].dropna(subset=['Src IP','Dst IP'])\n",
    "    df = bin_time(df, bin_seconds=bin_seconds)\n",
    "\n",
    "    edge_cols = [c for c in EDGE_COLS if c in df.columns]\n",
    "    for c in edge_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "    df[edge_cols] = df[edge_cols].replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
    "\n",
    "    # Edge feature scaler\n",
    "    if scaler_edge is None:\n",
    "        scaler_edge = StandardScaler()\n",
    "        fit_scaler = True\n",
    "    if fit_scaler and len(edge_cols) > 0:\n",
    "        scaler_edge.fit(df[edge_cols].astype(float).values)\n",
    "\n",
    "    ip2idx, n_nodes = make_ip_index(df)\n",
    "\n",
    "    # --- NEW: centralities over the full graph ---\n",
    "    C = compute_node_centralities_fast2( df, ip2idx,use_betweenness=False,     betw_samples=32,       pagerank_iters=40)\n",
    "\n",
    "    snapshots = []\n",
    "    prev_activity = defaultdict(int)  # lag-1 activity per node\n",
    "\n",
    "    # iterate bins\n",
    "    for b, g in df.sort_values('_bin').groupby('_bin'):\n",
    "        # Map nodes\n",
    "        src = g['Src IP'].map(ip2idx).astype(int).values\n",
    "        dst = g['Dst IP'].map(ip2idx).astype(int).values\n",
    "        edge_index = torch.tensor(np.vstack([src, dst]), dtype=torch.long)\n",
    "\n",
    "        # Edge attributes = scaled flow features + time encoding\n",
    "        if len(edge_cols) > 0:\n",
    "            eX = scaler_edge.transform(g[edge_cols].astype(float).values)\n",
    "        else:\n",
    "            eX = np.empty((len(g), 0), dtype=float)\n",
    "        # tfe = time_posenc(g['_epoch'].values)  # [E, 2*len(periods)]\n",
    "        # edge_attr_np = np.hstack([eX, tfe])\n",
    "        edge_attr_np = np.hstack([eX])\n",
    "        edge_attr = torch.tensor(edge_attr_np, dtype=torch.float)\n",
    "        edge_attr = torch.nan_to_num(edge_attr, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "        # Labels (edge-level)\n",
    "        y = torch.tensor(g[LABEL_COL].astype(int).values, dtype=torch.long)\n",
    "\n",
    "        # Node features:\n",
    "        #   (paper) centralities C; (yours) optional per-bin degrees + prev_activity\n",
    "        if include_per_bin_feats:\n",
    "            out_deg = np.bincount(src, minlength=n_nodes)\n",
    "            in_deg  = np.bincount(dst, minlength=n_nodes)\n",
    "            deg     = (out_deg + in_deg).reshape(-1,1)\n",
    "            node_feat = np.hstack([\n",
    "                in_deg.reshape(-1,1),\n",
    "                out_deg.reshape(-1,1),\n",
    "                deg,\n",
    "                np.array([prev_activity[i] for i in range(n_nodes)]).reshape(-1,1)\n",
    "            ])\n",
    "            node_feat = np.log1p(node_feat)\n",
    "            x_np = np.hstack([node_feat, C])  # [N, 4 + 5]\n",
    "        else:\n",
    "            x_np = C  # strict paper-style init\n",
    "\n",
    "        x = torch.tensor(x_np, dtype=torch.float)\n",
    "        x = torch.nan_to_num(x, nan=0.0, posinf=1e6, neginf=-1e6)\n",
    "\n",
    "        data = Data(\n",
    "            x=x,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=y\n",
    "        )\n",
    "        data._bin = int(b)\n",
    "        snapshots.append(data)\n",
    "\n",
    "        # Update prev_activity for next bin (count edges touched by node this bin)\n",
    "        touched = np.bincount(np.concatenate([src, dst]), minlength=n_nodes)\n",
    "        for i, c in enumerate(touched):\n",
    "            prev_activity[i] = int(c)\n",
    "\n",
    "    # Column names returned (only for info)\n",
    "    # time_cols = [f'time_{i}' for i in range(tfe.shape[1])]\n",
    "    # cent_cols = ['cent_degree','cent_betweenness','cent_closeness','cent_pagerank','cent_ktruss']\n",
    "    # edge_cols_used = edge_cols + time_cols + cent_cols\n",
    "\n",
    "    # time_cols = [f'time_{i}' for i in range(tfe.shape[1])]\n",
    "    cent_cols = ['cent_degree','cent_betweenness','cent_closeness','cent_pagerank','cent_ktruss']\n",
    "    edge_cols_used = edge_cols + cent_cols\n",
    "    return snapshots, ip2idx, scaler_edge, edge_cols_used"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "6472af76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:18:31.040373Z",
     "start_time": "2025-11-06T06:18:31.029906Z"
    }
   },
   "source": [
    "class EdgeGraphSAGEConv(MessagePassing):\n",
    "    \"\"\"\n",
    "    Edge-aware GraphSAGE (E-GraphSAGE-like):\n",
    "      m_ij = gate([x_i, x_j, e_ij]) * Ï†( Wj x_j + Wi x_i + We e_ij )\n",
    "      h_i' = Norm( mean_j m_ij + Wself x_i )     (residual)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, edge_in: int, out_channels: int, aggr: str = \"mean\", dropout: float = 0.0):\n",
    "        super().__init__(aggr=aggr, node_dim=0)\n",
    "        self.lin_src  = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.lin_dst  = nn.Linear(in_channels, out_channels, bias=False)\n",
    "        self.lin_edge = nn.Linear(edge_in,    out_channels, bias=False)\n",
    "        self.lin_self = nn.Linear(in_channels, out_channels, bias=True)\n",
    "\n",
    "        # Small gate that decides how much of each message passes through\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(in_channels + in_channels + edge_in, out_channels // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels // 2, 1)\n",
    "        )\n",
    "\n",
    "        self.norm = nn.LayerNorm(out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)  # -> [N, Fout]\n",
    "        out = out + self.lin_self(x)  # residual\n",
    "        out = self.norm(out)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i: torch.Tensor, x_j: torch.Tensor, edge_attr: torch.Tensor) -> torch.Tensor:\n",
    "        msg_raw = self.lin_src(x_j) + self.lin_dst(x_i) + self.lin_edge(edge_attr)\n",
    "        g = torch.sigmoid(self.gate(torch.cat([x_i, x_j, edge_attr], dim=-1)))\n",
    "        msg = F.relu(msg_raw) * g\n",
    "        return self.dropout(msg)\n",
    "\n",
    "    def update(self, aggr_out: torch.Tensor) -> torch.Tensor:\n",
    "        return aggr_out"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "ba02d20b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:18:31.125970Z",
     "start_time": "2025-11-06T06:18:31.109081Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class TemporalEdgeSAGEClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    GraphSAGE over each snapshot + GRUCell over node states across time.\n",
    "    Compatible with your EdgeGraphSAGEConv and edge-level head.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_node: int, in_edge: int, hidden: int = 128, num_layers: int = 2, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.hidden = hidden                    # <-- expose hidden\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # --- spatial backbone (edge-aware GraphSAGE) ---\n",
    "        from torch_geometric.nn import MessagePassing\n",
    "\n",
    "        class EdgeGraphSAGEConv(MessagePassing):\n",
    "            def __init__(self, in_channels, edge_in, out_channels, aggr=\"mean\", dropout=0.0):\n",
    "                super().__init__(aggr=aggr, node_dim=0)\n",
    "                self.lin_src  = nn.Linear(in_channels, out_channels, bias=False)\n",
    "                self.lin_dst  = nn.Linear(in_channels, out_channels, bias=False)\n",
    "                self.lin_edge = nn.Linear(edge_in,    out_channels, bias=False)\n",
    "                self.lin_self = nn.Linear(in_channels, out_channels, bias=True)\n",
    "                self.gate = nn.Sequential(\n",
    "                    nn.Linear(in_channels + in_channels + edge_in, out_channels // 2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(out_channels // 2, 1)\n",
    "                )\n",
    "                self.norm = nn.LayerNorm(out_channels)\n",
    "                self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "            def forward(self, x, edge_index, edge_attr):\n",
    "                out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "                out = out + self.lin_self(x)\n",
    "                out = self.norm(out)\n",
    "                return out\n",
    "\n",
    "            def message(self, x_i, x_j, edge_attr):\n",
    "                msg_raw = self.lin_src(x_j) + self.lin_dst(x_i) + self.lin_edge(edge_attr)\n",
    "                g = torch.sigmoid(self.gate(torch.cat([x_i, x_j, edge_attr], dim=-1)))\n",
    "                msg = F.relu(msg_raw) * g\n",
    "                return self.dropout(msg)\n",
    "\n",
    "            def update(self, aggr_out):\n",
    "                return aggr_out\n",
    "\n",
    "        layers = []\n",
    "        dims = [in_node] + [hidden] * num_layers\n",
    "        for i in range(num_layers):\n",
    "            layers.append(EdgeGraphSAGEConv(dims[i], in_edge, dims[i+1], aggr=\"mean\", dropout=dropout))\n",
    "        self.convs = nn.ModuleList(layers)\n",
    "\n",
    "        # --- temporal cell over nodes ---\n",
    "        self.gru = nn.GRUCell(hidden, hidden)\n",
    "\n",
    "        # --- edge head (uses recurrent node states) ---\n",
    "        edge_head_in = (2 * hidden) + in_edge + hidden + hidden  # [h_s, h_d, e, |h_s-h_d|, h_s*h_d]\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(edge_head_in, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden, 2)\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def init_state(self, num_nodes: int, device=None):\n",
    "        \"\"\"Create zero initial node states of shape [num_nodes, hidden].\"\"\"\n",
    "        return torch.zeros(num_nodes, self.hidden, device=device)\n",
    "\n",
    "    def spatial_encode(self, data: Data) -> torch.Tensor:\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index, edge_attr)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "        return x  # [N, hidden]\n",
    "\n",
    "    def forward(self, data: Data, h_prev: torch.Tensor | None = None) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Returns (edge_logits, h_t)\n",
    "        \"\"\"\n",
    "        x_star = self.spatial_encode(data)                     # [N, H]\n",
    "        if h_prev is None:\n",
    "            h_prev = x_star.new_zeros(x_star.size(0), x_star.size(1))\n",
    "        h_t = self.gru(x_star, h_prev)                         # [N, H]\n",
    "\n",
    "        src, dst = data.edge_index\n",
    "        h_s, h_d = h_t[src], h_t[dst]\n",
    "        h_abs = torch.abs(h_s - h_d)\n",
    "        h_mul = h_s * h_d\n",
    "        z = torch.cat([h_s, h_d, data.edge_attr, h_abs, h_mul], dim=-1)\n",
    "        logits = self.edge_mlp(z)\n",
    "        return logits, h_t\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "e4fcd6eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:18:31.177029Z",
     "start_time": "2025-11-06T06:18:31.169193Z"
    }
   },
   "source": [
    "def run_epoch_fullgraph(model, snapshots, optimizer=None, device='cpu'):\n",
    "    is_train = optimizer is not None\n",
    "    total_loss, total_correct, total_edges = 0.0, 0, 0\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    all_preds, all_trues = [], []\n",
    "\n",
    "    for data in snapshots:\n",
    "        data = data.to(device)\n",
    "        logits = model(data)\n",
    "        if is_train:\n",
    "            loss = ce(logits, data.y)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "            optimizer.step()\n",
    "            total_loss += float(loss.item()) * data.y.numel()\n",
    "        with torch.no_grad():\n",
    "            pred = logits.argmax(dim=1)\n",
    "            all_preds.append(pred.cpu().numpy())\n",
    "            all_trues.append(data.y.cpu().numpy())\n",
    "            total_correct += int((pred == data.y).sum())\n",
    "            total_edges += int(data.y.numel())\n",
    "\n",
    "    # Metrics\n",
    "    if all_trues:\n",
    "        y_true = np.concatenate(all_trues)\n",
    "        y_pred = np.concatenate(all_preds)\n",
    "        weighted_f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        # FPR: FP / N_negatives\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "        tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0,0,0,0)\n",
    "        fpr = fp / max(1, (fp + tn))\n",
    "    else:\n",
    "        weighted_f1, fpr = float('nan'), float('nan')\n",
    "\n",
    "    avg_loss = (total_loss / max(1, total_edges)) if is_train else None\n",
    "    acc = total_correct / max(1, total_edges)\n",
    "    return avg_loss, acc, weighted_f1, fpr"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:09:09.074024Z",
     "start_time": "2025-11-06T06:09:09.057718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AsymmetricLoss(torch.nn.Module):\n",
    "    def __init__(self, gamma_pos=0.0, gamma_neg=2.0, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.gp, self.gn, self.eps = gamma_pos, gamma_neg, eps\n",
    "    def forward(self, logits, y):\n",
    "        p = torch.softmax(logits, dim=1)[:,1]\n",
    "        yf = y.float()\n",
    "        pt = p*yf + (1-p)*(1-yf)\n",
    "        gamma = self.gp*yf + self.gn*(1-yf)\n",
    "        loss = - (yf*torch.log(p+self.eps) + (1-yf)*torch.log(1-p+self.eps)) * ((1-pt)**gamma)\n",
    "        return loss.mean()\n",
    "\n",
    "# in training:\n",
    "\n"
   ],
   "id": "1c8e70cb68d10632",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "1a2a7676",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:18:31.225062Z",
     "start_time": "2025-11-06T06:18:31.209276Z"
    }
   },
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "def run_epoch_neighbor_temporal(\n",
    "    model,\n",
    "    snapshots,\n",
    "    optimizer=None,\n",
    "    device='cuda',\n",
    "    num_neighbors=[25, 10],\n",
    "    batch_size=4096,\n",
    "    shuffle=True,\n",
    "    clip=2.0,\n",
    "    tbptt=5,                 # detach global state every N mini-batches to cap memory\n",
    "):\n",
    "    \"\"\"\n",
    "    If optimizer is None -> eval mode (no loss/updates, returns avg_loss=None).\n",
    "    Maintains a global H over nodes; per mini-batch we read/write H[batch.n_id].\n",
    "    \"\"\"\n",
    "    is_train = optimizer is not None\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    model.train() if is_train else model.eval()\n",
    "\n",
    "    # All snapshots in a split share the same node index space\n",
    "    N = snapshots[0].x.size(0)\n",
    "    H_global = torch.zeros(N, model.hidden, device=device)\n",
    "\n",
    "    total_loss, total_correct, total_edges = 0.0, 0, 0\n",
    "    all_preds, all_trues = [], []\n",
    "    steps_since_detach = 0\n",
    "\n",
    "    # Process snapshots in chronological order\n",
    "    for snap in sorted(snapshots, key=lambda d: getattr(d, \"_bin\", 0)):\n",
    "        loader = NeighborLoader(\n",
    "            snap, num_neighbors=num_neighbors, batch_size=batch_size, shuffle=shuffle\n",
    "        )\n",
    "        for batch in loader:\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # Map global node states -> batch node states\n",
    "            h_prev_batch = H_global[batch.n_id]                         # [N_batch_nodes, H]\n",
    "            logits, h_t_batch = model(batch, h_prev=h_prev_batch)       # (edge_logits, new_node_states)\n",
    "\n",
    "            if is_train:\n",
    "                loss = ce(logits, batch.y)\n",
    "                if torch.isfinite(loss):\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "                    optimizer.step()\n",
    "                    total_loss += float(loss.item()) * batch.y.numel()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred = logits.argmax(1)\n",
    "                all_preds.append(pred.detach().cpu().numpy())\n",
    "                all_trues.append(batch.y.detach().cpu().numpy())\n",
    "                total_correct += int((pred == batch.y).sum())\n",
    "                total_edges   += int(batch.y.numel())\n",
    "\n",
    "                # Write back updated node states for nodes seen in this subgraph\n",
    "                H_global[batch.n_id] = h_t_batch.detach()\n",
    "\n",
    "            # Truncated BPTT: periodically detach the whole global state\n",
    "            steps_since_detach += 1\n",
    "            if is_train and steps_since_detach >= tbptt:\n",
    "                H_global = H_global.detach()\n",
    "                steps_since_detach = 0\n",
    "\n",
    "    # Metrics\n",
    "    if all_trues:\n",
    "        y_true = np.concatenate(all_trues)\n",
    "        y_pred = np.concatenate(all_preds)\n",
    "        weighted_f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "        tn, fp, fn, tp = cm.ravel() if cm.size == 4 else (0, 0, 0, 0)\n",
    "        fpr = fp / max(1, (fp + tn))\n",
    "        acc = (y_pred == y_true).mean()\n",
    "    else:\n",
    "        weighted_f1, fpr, acc = float('nan'), float('nan'), float('nan')\n",
    "\n",
    "    avg_loss = (total_loss / max(1, total_edges)) if is_train else None\n",
    "    return avg_loss, acc, weighted_f1, fpr\n"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3f867f79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:19:54.854673Z",
     "start_time": "2025-11-06T06:18:58.813746Z"
    }
   },
   "source": "train_df = pd.read_csv('train.csv')\n",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:18:58.788007Z",
     "start_time": "2025-11-06T06:18:45.731010Z"
    }
   },
   "cell_type": "code",
   "source": "test_df = pd.read_csv('test.csv')",
   "id": "f409b326a15f9232",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:19:54.914078Z",
     "start_time": "2025-11-06T06:19:54.897496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def optimize_numeric_dtypes(df: pd.DataFrame, try_float16: bool = False, verbose: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Downcast numeric columns to the smallest possible dtype without changing values.\n",
    "    - Integers: downcast to smallest signed/unsigned integer.\n",
    "    - Floats: downcast to float32 (and optionally float16 if lossless within tolerance).\n",
    "    Returns a new DataFrame (original unchanged).\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    start_mem = result.memory_usage(deep=True).sum() / 1024**2\n",
    "\n",
    "    num_cols = [c for c in result.columns if pd.api.types.is_numeric_dtype(result[c])]\n",
    "    for c in num_cols:\n",
    "        col = result[c]\n",
    "\n",
    "        # Skip all-NaN\n",
    "        if col.notnull().sum() == 0:\n",
    "            continue\n",
    "\n",
    "        if pd.api.types.is_integer_dtype(col):\n",
    "            # Integer (no NaNs)\n",
    "            if col.min() >= 0:\n",
    "                result[c] = pd.to_numeric(col, downcast=\"unsigned\")\n",
    "            else:\n",
    "                result[c] = pd.to_numeric(col, downcast=\"integer\")\n",
    "\n",
    "        elif pd.api.types.is_float_dtype(col):\n",
    "            # First, try float32\n",
    "            col32 = col.astype(np.float32)\n",
    "            if np.allclose(col.values, col32.values, equal_nan=True):\n",
    "                result[c] = col32\n",
    "                # Optionally try float16 (more aggressive)\n",
    "                if try_float16:\n",
    "                    col16 = col.astype(np.float16)\n",
    "                    if np.allclose(col.values, col16.astype(np.float32).values, rtol=1e-03, atol=1e-06, equal_nan=True):\n",
    "                        result[c] = col16\n",
    "            # else keep original float64\n",
    "\n",
    "        # If it's a nullable integer (Int64/Int32), try to preserve nulls with the smallest nullable int\n",
    "        elif pd.api.types.is_dtype_equal(col.dtype, \"Int64\") or str(col.dtype).startswith(\"Int\"):\n",
    "            if col.min() >= 0:\n",
    "                tmp = pd.to_numeric(col.astype(\"float64\"), downcast=\"unsigned\")\n",
    "            else:\n",
    "                tmp = pd.to_numeric(col.astype(\"float64\"), downcast=\"integer\")\n",
    "            # Cast back to nullable integer if still integer-like\n",
    "            if pd.api.types.is_integer_dtype(tmp):\n",
    "                result[c] = pd.Series(tmp, index=col.index).astype(pd.ArrowDtype(tmp.dtype.name) if hasattr(pd, \"ArrowDtype\") else tmp.dtype)\n",
    "\n",
    "    end_mem = result.memory_usage(deep=True).sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f\"Memory: {start_mem:.2f} MB â†’ {end_mem:.2f} MB ({(start_mem-end_mem):.2f} MB saved, {(1 - end_mem/max(start_mem,1e-9))*100:.1f}% reduction)\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# --- Example ---\n",
    "# df_optimized = optimize_numeric_dtypes(df, try_float16=False, verbose=True)\n"
   ],
   "id": "1981f38243bd087e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:20:36.226891Z",
     "start_time": "2025-11-06T06:19:55.000035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_df_small = optimize_numeric_dtypes(train_df.copy(), True, True)\n",
    "test_df_small = optimize_numeric_dtypes(test_df.copy(), True, True)\n",
    "\n"
   ],
   "id": "bb6f7cccec9383cb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alice\\PycharmProjects\\co-simulation-code\\.venv1\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:170: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: 7706.79 MB â†’ 6101.18 MB (1605.61 MB saved, 20.8% reduction)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alice\\PycharmProjects\\co-simulation-code\\.venv1\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:170: RuntimeWarning: overflow encountered in cast\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory: 1926.65 MB â†’ 1525.25 MB (401.40 MB saved, 20.8% reduction)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "1d30bbd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:20:36.332724Z",
     "start_time": "2025-11-06T06:20:36.323362Z"
    }
   },
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:20:36.401048Z",
     "start_time": "2025-11-06T06:20:36.387079Z"
    }
   },
   "cell_type": "code",
   "source": "device",
   "id": "162787adc5e6f26d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:25:06.383698Z",
     "start_time": "2025-11-06T06:22:14.339088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build train snapshots (fit scaler)\n",
    "train_snaps, train_ip2idx, scaler_edge, edge_cols_used = build_snapshots(\n",
    "    train_df_small, scaler_edge=None, fit_scaler=True, bin_seconds=300, device=device, include_per_bin_feats=False\n",
    ")\n",
    "\n",
    "# Build test snapshots (reuse scaler; separate ip2idx for strict inductive)\n",
    "test_snaps, test_ip2idx, _, _ = build_snapshots(\n",
    "    test_df_small, scaler_edge=scaler_edge, fit_scaler=False, bin_seconds=300, device=device, include_per_bin_feats=False\n",
    ")"
   ],
   "id": "174984bbd266c9b2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "0b8b4853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:25:12.886487Z",
     "start_time": "2025-11-06T06:25:11.778523Z"
    }
   },
   "source": [
    "in_node = train_snaps[0].x.size(1)         # now includes centralities (+ optional per-bin feats)\n",
    "in_edge = train_snaps[0].edge_attr.size(1) # edge features + time enc\n",
    "model = TemporalEdgeSAGEClassifier(in_node=in_node, in_edge=in_edge,\n",
    "                                hidden=32, num_layers=2, dropout=0.2).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:54:18.713740Z",
     "start_time": "2025-11-06T06:25:16.575298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # Train across ALL train snapshots (temporal state is carried within the function)\n",
    "    tr_loss, tr_acc, tr_f1, tr_fpr = run_epoch_neighbor_temporal(\n",
    "        model, train_snaps, optimizer=opt, device=device,\n",
    "        num_neighbors=[25,10], batch_size=4096, shuffle=True, tbptt=5\n",
    "    )\n",
    "\n",
    "    # Evaluate across ALL test snapshots (no optimizer = eval)\n",
    "    _, te_acc, te_f1, te_fpr = run_epoch_neighbor_temporal(\n",
    "        model, test_snaps, optimizer=None, device=device,\n",
    "        num_neighbors=[25,10], batch_size=4096, shuffle=False, tbptt=5\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"train loss {tr_loss:.4f} | train acc {tr_acc:.4f} | \"\n",
    "        f\"train F1 {tr_f1:.4f} | train FPR {tr_fpr:.4f} | \"\n",
    "        f\"test acc {te_acc:.4f} | test F1 {te_f1:.4f} | test FPR {te_fpr:.4f}\"\n",
    "    )\n"
   ],
   "id": "1429b2e9f8c53c98",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train loss 0.0004 | train acc 1.0000 | train F1 1.0000 | train FPR 0.0000 | test acc 0.9999 | test F1 0.9999 | test FPR 0.0000\n",
      "Epoch 02 | train loss 0.0001 | train acc 1.0000 | train F1 1.0000 | train FPR 0.0000 | test acc 0.9998 | test F1 0.9998 | test FPR 0.0002\n",
      "Epoch 03 | train loss 0.0001 | train acc 1.0000 | train F1 1.0000 | train FPR 0.0000 | test acc 1.0000 | test F1 1.0000 | test FPR 0.0000\n",
      "Epoch 04 | train loss 0.0001 | train acc 1.0000 | train F1 1.0000 | train FPR 0.0000 | test acc 1.0000 | test F1 1.0000 | test FPR 0.0000\n",
      "Epoch 05 | train loss 0.0000 | train acc 1.0000 | train F1 1.0000 | train FPR 0.0000 | test acc 0.9999 | test F1 1.0000 | test FPR 0.0001\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9d93fe9523a26c6a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:54:45.603853Z",
     "start_time": "2025-11-06T06:54:45.593153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "@torch.no_grad()\n",
    "def confusion_and_plot_temporal(model, snapshots, device='cuda', labels=(0, 1), title='Confusion Matrix (Test)'):\n",
    "    \"\"\"\n",
    "    Evaluate a temporal GNN across snapshots in chronological order,\n",
    "    carrying node state across time. Plots and returns the confusion matrix.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Sort by time and init recurrent state\n",
    "    snaps = sorted(snapshots, key=lambda d: getattr(d, \"_bin\", 0))\n",
    "    N0 = snaps[0].x.size(0)\n",
    "    hidden_dim = getattr(model, \"hidden\", None) or model.gru.hidden_size\n",
    "    H = torch.zeros(N0, hidden_dim, device=device)\n",
    "\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    for snap in snaps:\n",
    "        snap = snap.to(device)\n",
    "\n",
    "        # If node count differs, re-init state (e.g., different split)\n",
    "        if H.size(0) != snap.x.size(0):\n",
    "            H = torch.zeros(snap.x.size(0), hidden_dim, device=device)\n",
    "\n",
    "        logits, H = model(snap, H)  # temporal forward\n",
    "        preds  = logits.argmax(dim=1).cpu().numpy()\n",
    "        labels_np = snap.y.cpu().numpy()\n",
    "\n",
    "        all_preds.append(preds)\n",
    "        all_labels.append(labels_np)\n",
    "\n",
    "        H = H.detach()  # truncate (safety)\n",
    "\n",
    "    y_pred = np.concatenate(all_preds) if all_preds else np.array([])\n",
    "    y_true = np.concatenate(all_labels) if all_labels else np.array([])\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(labels))\n",
    "    report = classification_report(y_true, y_pred, labels=list(labels), digits=4, zero_division=0)\n",
    "\n",
    "    # --- Plot above the text output ---\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(\n",
    "        cm, annot=True, fmt='d', cmap='Blues',\n",
    "        xticklabels=[f'Pred {l}' for l in labels],\n",
    "        yticklabels=[f'True {l}' for l in labels]\n",
    "    )\n",
    "    plt.xlabel('Predicted'); plt.ylabel('True'); plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"ðŸ“Š Classification Report:\")\n",
    "    print(report)\n",
    "    return cm, report\n"
   ],
   "id": "ad8666e2aec4079f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T06:54:53.266994Z",
     "start_time": "2025-11-06T06:54:49.410461Z"
    }
   },
   "cell_type": "code",
   "source": "cm, report = confusion_and_plot_temporal(model, test_snaps, device=device)\n",
   "id": "9a756ab748ec0907",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000   5391219\n",
      "           1     0.9999    1.0000    0.9999   1084194\n",
      "\n",
      "    accuracy                         1.0000   6475413\n",
      "   macro avg     0.9999    1.0000    1.0000   6475413\n",
      "weighted avg     1.0000    1.0000    1.0000   6475413\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
